# â¤ï¸ Heart Disease Prediction System - TensorFlow Implementation

**ğŸ“ Adamas University - Python Project**

> **ğŸ“– Documentation Guide:**
> - **README.md** (this file) - ğŸš€ Quick start and main overview
> - **COMPLETE_GUIDANCE.md** - ğŸ“š Comprehensive technical documentation (5000+ words)
> - **TERMS.md** - ğŸ” Glossary of ML and medical terms
> - **[LICENSE](LICENSE)** - ğŸ“‹ Project information, team, and requirements

## ğŸ“‹ Overview

This project implements a **ğŸ§  Machine Learning-based Heart Disease Prediction System** using **TensorFlow Neural Networks** for advanced deep learning capabilities.

### Main Components:
- **`disease_tensorflow.py`** - ğŸ’» Complete TensorFlow neural network implementation (RECOMMENDED)
- **`disease.py`** - ğŸ“¦ Legacy XGBoost implementation (for reference only)
- ğŸ”„ Comprehensive data preprocessing pipeline
- ğŸ¯ Advanced neural network architecture with regularization
- ğŸ“Š Multiple evaluation metrics and visualizations
- ğŸ’¬ Interactive prediction interface

## ğŸ“ Directory Structure

```
TensorFlow/
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â””â”€â”€ ğŸ“„ heart_disease.csv              # ğŸ“Š Dataset (10,000 samples, 21 features)
â”‚
â”œâ”€â”€ ğŸ“‚ train/                             # ğŸ† Generated after first run
â”‚   â”œâ”€â”€ ğŸ¤– tf_heart_model.keras           # ğŸ§  Trained TensorFlow model
â”‚   â”œâ”€â”€ ğŸ“¦ scaler.pkl                     # ğŸ”„ StandardScaler for feature normalization
â”‚   â”œâ”€â”€ ğŸ“¦ label_encoders.pkl             # ğŸ·ï¸ LabelEncoders for categorical features
â”‚   â”œâ”€â”€ ğŸ“¦ feature_order.pkl              # âœ… Feature ordering (for consistency)
â”‚   â”œâ”€â”€ ğŸ“ˆ training_history.png           # ğŸ“Š Training/validation curves
â”‚   â”œâ”€â”€ ğŸ“‰ roc_curve.png                  # ğŸ¯ ROC curve with AUC score
â”‚   â”œâ”€â”€ ğŸ”¥ confusion_matrix.png           # ğŸ“ Confusion matrix heatmap
â”‚   â”œâ”€â”€ ğŸ“Š prediction_distribution.png    # ğŸ“ˆ Histogram of predictions
â”‚   â””â”€â”€ ğŸ¨ performance_summary.png        # ğŸ“Š Metrics bar chart
â”‚
â”œâ”€â”€ ğŸ’» disease_tensorflow.py              # ğŸŒŸ Main TensorFlow implementation â­
â”œâ”€â”€ ğŸ“œ disease.py                         # ğŸ—‚ï¸ Legacy XGBoost (reference only)
â”œâ”€â”€ ğŸ“„ README.md                          # ğŸ“– This file
â””â”€â”€ ğŸ“š COMPLETE_GUIDANCE.md               # ğŸ”¬ Detailed implementation guide
```

## ğŸš€ Quick Start

### ğŸŒŸ Primary Implementation (TensorFlow)
```bash
python disease_tensorflow.py
```

**âš™ï¸ This script performs all steps automatically:**
1. **Phase 1ï¸âƒ£:** ğŸ“¥ Data loading & preprocessing
2. **Phase 2ï¸âƒ£:** ğŸ§  Neural network training
3. **Phase 3ï¸âƒ£:** ğŸ“Š Model evaluation & metrics
4. **Phase 4ï¸âƒ£:** ğŸ¨ Generate 5 visualizations
5. **Phase 5ï¸âƒ£:** ğŸ’¬ Interactive prediction interface

### ğŸ“¦ Legacy Implementation (XGBoost - Reference Only)
```bash
python disease.py  # âš ï¸ Not recommended - use TensorFlow version
```

## ğŸ“Š Dataset

**ğŸ“„ File:** `data/heart_disease.csv`

**ğŸ“‹ Features (21 total):**
- ğŸ‘¤ Demographics: Age, Gender
- ğŸ’“ Vital Signs: Blood Pressure
- ğŸ©¸ Lipids: Cholesterol Level, Triglyceride Level, LDL Cholesterol, HDL Cholesterol
- ğŸ¥ Medical History: Smoking, Diabetes, Family Heart Disease
- ğŸƒ Lifestyle: Exercise Habits, Alcohol Consumption, Stress Level, Sleep Hours, Sugar Consumption
- âš•ï¸ Health Markers: BMI, High Blood Pressure, Fasting Blood Sugar, CRP Level, Homocysteine Level

**ğŸ¯ Target:** Heart Disease Status (Binary: Yes/No)

## ğŸ§  Neural Network Architecture

### ğŸ—ï¸ Model Structure (TensorFlow/Keras Sequential)
```
ğŸ“¥ Input Layer
    â†“ (20 features - all numeric after preprocessing)
ğŸ§  Dense(256, activation='relu', L2=0.001)
    â†“
âš™ï¸ BatchNormalization()
    â†“
ğŸ”„ Dropout(0.4)  â† 40% dropout for regularization
    â†“
ğŸ§  Dense(128, activation='relu', L2=0.001)
    â†“
âš™ï¸ BatchNormalization()
    â†“
ğŸ”„ Dropout(0.3)  â† 30% dropout
    â†“
ğŸ§  Dense(64, activation='relu', L2=0.001)
    â†“
âš™ï¸ BatchNormalization()
    â†“
ğŸ”„ Dropout(0.2)  â† 20% dropout
    â†“
ğŸ§  Dense(32, activation='relu')
    â†“
ğŸ§  Dense(16, activation='relu')
    â†“
ğŸ“¤ Dense(1, activation='sigmoid')  â† ğŸ’¯ Binary output [0, 1]
```

### ğŸ¯ Key Design Choices:
- **ğŸ“Š Total Parameters:** ~142,000
- **âš¡ Optimizer:** Adam (lr=0.001) - Adaptive learning rate optimization
- **ğŸ“‰ Loss Function:** Binary Crossentropy - Standard for binary classification
- **ğŸ›¡ï¸ Regularization Techniques:**
  - ğŸ“Œ L2 Penalty (0.001) - Prevents overfitting by penalizing large weights
  - ğŸ”€ Dropout (0.2-0.4) - Randomly deactivates neurons during training
  - âš™ï¸ Batch Normalization - Normalizes layer inputs for faster convergence
- **â¹ï¸ Early Stopping:** Patience=50 - Stops training if validation loss doesn't improve
- **ğŸ“ˆ Learning Rate Scheduler:** Reduces LR by 0.5 if no improvement for 10 epochs

## ğŸ”„ Data Preprocessing Pipeline

### âœ… Step 1: Missing Value Handling
```python
# ğŸ“Š Numeric columns: Use median (less affected by outliers)
# ğŸ·ï¸ Categorical columns: Use mode (most frequent value)
```
- **â“ Why median for numeric?** Robust to outliers, appropriate for skewed distributions
- **â“ Why mode for categorical?** Preserves most frequent pattern in data

### âœ… Step 2: Categorical Encoding (LabelEncoder)
- ğŸ”„ Converts categorical strings to numeric integers
- ğŸ“ Example: `['Male', 'Female']` â†’ `[1, 0]`
- âœ”ï¸ Maintains order consistency across train/test sets

### âœ… Step 3: Feature Scaling (StandardScaler)
```
scaled_value = (x - mean) / std_dev
```
- **â“ Why scaling?** Neural networks converge faster with normalized inputs
- ğŸš« Prevents features with larger scales from dominating
- ğŸ“Š All features now on same scale ~[-3, 3]

### âœ… Step 4: Train-Test Split
- **ğŸ“Š 80-20 split:** 80% training, 20% testing
- **âœ”ï¸ Stratification:** Maintains class distribution in both sets
- **ğŸ” Random state:** Ensures reproducibility

### âœ… Step 5: Class Weight Balancing
- **âš ï¸ Problem:** Dataset may have imbalanced classes (more healthy than diseased)
- **ğŸ’¡ Solution:** Assign higher weights to minority class
- **âœ¨ Effect:** Model learns both classes equally well

## ğŸ“Š Evaluation Metrics

After training, you'll see:

```
âœ… Train Accuracy: XX.XX%
âœ… Test Accuracy:  XX.XX%
ğŸ“ˆ Train AUC-ROC:  X.XXXX
ğŸ“ˆ Test AUC-ROC:   X.XXXX

ğŸ“‹ Classification Report:
              precision    recall  f1-score   support
    No Disease       X.XX      X.XX      X.XX       XXX
       Disease       X.XX      X.XX      X.XX       XXX

ğŸ”¥ Confusion Matrix:
 [[TN  FP]
  [FN  TP]]
```

## ğŸ¨ Generated Visualizations

1. **ğŸ“ˆ 01_training_history.png**
   - ğŸ“Š Training vs Validation Accuracy
   - ğŸ“‰ Training vs Validation Loss
   - ğŸ“Š Training vs Validation AUC-ROC

2. **ğŸ“Š 02_roc_curve.png**
   - ğŸ¯ ROC Curve with AUC score
   - ğŸ”„ Comparison with random classifier

3. **ğŸ”¥ 03_confusion_matrix.png**
   - âœ… True Negatives, False Positives
   - âŒ False Negatives, True Positives

4. **ğŸ“ˆ 04_prediction_distribution.png**
   - ğŸ“Š Distribution of predictions for both classes
   - ğŸ“ Decision threshold visualization

5. **ğŸ“Š 05_performance_summary.png**
   - ğŸ“Š Bar chart of: Accuracy, AUC-ROC, Precision, Recall

## ğŸ’» Making Predictions

### ğŸ’¬ Interactive Mode
```bash
python complete_system.py
# 1ï¸âƒ£ Select option [1] to make a prediction
# 2ï¸âƒ£ Enter patient details when prompted
```

### ğŸ“¤ Output
```
ğŸ‘¤ Patient Details:
  ğŸ‘¶ Age: 55
  ğŸ‘¨ Gender: Male
  ...
  
âœ… LOW RISK: No heart disease detected (Confidence: 87.3%)
```

## ğŸ”§ Configuration

All configurations are in the scripts:
- ğŸ“‚ `SCRIPT_DIR`: Working directory
- ğŸ“‚ `OUTPUT_DIR`: Model output location
- ğŸ“‚ `DATA_PATH`: Dataset location
- âš™ï¸ `MODEL_PARAMS`: Neural network hyperparameters

To modify model architecture, edit these sections in the scripts:
```python
model = tf.keras.Sequential([
    # ğŸ”§ Modify layers here
])
```

## ğŸ“¦ Dependencies

```
ğŸ“¦ pandas>=1.3.0
ğŸ“¦ numpy>=1.21.0
ğŸ¤– tensorflow>=2.10.0
ğŸ“š scikit-learn>=1.0.0
ğŸ¨ matplotlib>=3.4.0
ğŸ¨ seaborn>=0.11.0
```

ğŸ“¥ Install with:
```bash
pip install pandas numpy tensorflow scikit-learn matplotlib seaborn
```

## âš ï¸ Important Notes

1. **ğŸš€ First Run:** Always run `train_model.py` or `complete_system.py` first to train the model
2. **ğŸ’¾ Model Path:** The trained model is saved in `train/` directory
3. **ğŸ“‹ Feature Order:** Must maintain consistent feature order between training and prediction
4. **ğŸ·ï¸ Encoding:** Categorical variables are encoded and must be decoded for display
5. **ğŸ“Š Scaling:** Features are always scaled before prediction

## ğŸ”„ Migration from Old System

The new TensorFlow-only system replaces:
- `disease.py` (XGBoost) â†’ âŒ Not used
- `disease_tensorflow.py` (mixed) â†’ âœ… Use `train_model.py` or `complete_system.py`

## ğŸ“ Files Explanation

| ğŸ“„ File | ğŸ¯ Purpose |
|------|---------|
| `train_model.py` | ğŸš€ Standalone training with full evaluation |
| `predict.py` | ğŸ’¬ Interactive prediction after training |
| `complete_system.py` | ğŸŒ All-in-one solution (train + evaluate + predict) |
| `disease.py` | âŒ OLD: XGBoost version (deprecated) |
| `disease_tensorflow.py` | âš ï¸ OLD: Mixed implementation (deprecated) |

## ğŸ¯ Performance Targets

ğŸ“Š Typical model performance:
- **âœ… Accuracy:** 85-90%
- **ğŸ“ˆ AUC-ROC:** 0.90-0.95
- **ğŸ¯ Precision:** 0.85-0.92
- **ğŸ“ Recall:** 0.82-0.88

*Actual values depend on data and hyperparameters*

## ğŸ› Troubleshooting

### âŒ "Model not found" error
**âœ… Solution:** Run `train_model.py` or `complete_system.py` first

### âŒ "CSV file not found" error
**âœ… Solution:** Ensure `data/heart_disease.csv` exists in the same directory

### âŒ Out of Memory error
**âœ… Solution:** Reduce batch_size in the model configuration

### âŒ Low accuracy
**âœ… Solution:** 
- ğŸ” Check data quality
- âš™ï¸ Adjust hyperparameters
- ğŸ“ˆ Increase epochs
- ğŸ—ï¸ Modify model architecture

## ğŸ“§ Support

For issues or questions about:
- **ğŸ”„ Data preprocessing:** Check `load_and_prepare_data()` function
- **ğŸ§  Model training:** Check `train_model()` function
- **ğŸ’¬ Predictions:** Check `make_prediction()` function

## âœ¨ Features

âœ… Pure TensorFlow implementation
âœ… Handles missing values
âœ… Encodes categorical variables
âœ… Balances imbalanced classes
âœ… Early stopping to prevent overfitting
âœ… Learning rate scheduling
âœ… Comprehensive evaluation metrics
âœ… Beautiful visualizations
âœ… Interactive prediction interface
âœ… Model persistence (save/load)
âœ… Well documented code
âœ… Error handling

## ğŸ“š For More Information

**ğŸ“– For detailed technical information**, see **COMPLETE_GUIDANCE.md** which includes:
- ğŸ—ï¸ Complete system architecture explanation
- ğŸ“š Library packages and why TensorFlow was chosen over XGBoost
- ğŸ§  Neural network layer-by-layer breakdown
- ğŸ”„ Data preprocessing pipeline details
- ğŸ“š Training and evaluation process explanation
- ğŸ“Š Output interpretation and metric explanations
- ğŸ› Troubleshooting guide

**ğŸ” For glossary of terms**, see **TERMS.md** which includes:
- ğŸ”¥ Confusion Matrix, Precision, Recall, Accuracy explained
- ğŸ“ˆ AUC-ROC, ROC Curve, F1-Score definitions
- âš™ï¸ Epoch, Loss, Gradient, Learning Rate concepts
- ğŸšï¸ Decision Threshold, Regularization techniques
- âš•ï¸ Medical-specific concepts (Sensitivity, Specificity, PPV, NPV)

**ğŸ“‹ For project details**, see **[LICENSE](LICENSE)** which includes:
- ğŸ‘¥ Complete team information
- ğŸ“‹ Project requirements and specifications
- ğŸ“¥ Installation instructions
- âš™ï¸ Technical specifications
- ğŸ› Troubleshooting guide

## ğŸš€ Future Enhancements

- [ ] âœ”ï¸ Cross-validation
- [ ] ğŸ”§ Hyperparameter tuning with Optuna
- [ ] ğŸ” Model interpretation (SHAP values)
- [ ] ğŸŒ API server (Flask/FastAPI)
- [ ] ğŸ’» Web interface
- [ ] ğŸ“Š Real-time prediction monitoring
- [ ] ğŸ“¦ Model versioning

## ğŸ‘¥ Development Team

**ğŸ“ Adamas University - Python Project**

### ğŸ† Lead Developers
- **ğŸ‘¨â€ğŸ’» Rohit Kumar Adak** 
- **ğŸ‘¨â€ğŸ’» Babin Bid** 

### ğŸ’¼ Developers
- **ğŸ‘©â€ğŸ’» Ritika Pramanick** 
- **ğŸ‘©â€ğŸ’» Liza Ghosh** 

## ğŸ“… Project Timeline

- **ğŸ“… Start Date:** November 2025
- **ğŸ“… Last Modification:** 8th November 2025
- **ğŸ”¢ Version:** 1.0
- **âœ… Status:** âœ… Complete

---

<div align="center">

**ğŸ“ Created:** November 2025 | **ğŸ”¢ Version:** 1.0 | **ğŸ¤– Framework:** TensorFlow 2.x

**ğŸ“œ License:** MIT (See [LICENSE](LICENSE) file) | **ğŸ« Institution:** Adamas University

</div>
