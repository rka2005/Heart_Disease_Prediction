# Heart Disease Prediction System - TensorFlow Implementation

**Adamas University - Python Project**

> **üìñ Documentation Guide:**
> - **README.md** (this file) - Quick start and main overview
> - **COMPLETE_GUIDANCE.md** - Comprehensive technical documentation (5000+ words)
> - **TERMS.md** - Glossary of ML and medical terms
> - **LICENSE** - Project information, team, and requirements

## üìã Overview

This project implements a **Machine Learning-based Heart Disease Prediction System** using both TensorFlow and legacy XGBoost approaches. The primary system uses **TensorFlow Neural Networks** for advanced deep learning capabilities.

### Main Components:
- **`disease_tensorflow.py`** - Complete TensorFlow neural network implementation (RECOMMENDED)
- **`disease.py`** - Legacy XGBoost implementation (for reference only)
- Comprehensive data preprocessing pipeline
- Advanced neural network architecture with regularization
- Multiple evaluation metrics and visualizations
- Interactive prediction interface

## üìÅ Directory Structure

```
TensorFlow/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ heart_disease.csv              # Dataset (10,000 samples, 21 features)
‚îÇ
‚îú‚îÄ‚îÄ train/                             # Generated after first run
‚îÇ   ‚îú‚îÄ‚îÄ tf_heart_model.keras           # Trained TensorFlow model
‚îÇ   ‚îú‚îÄ‚îÄ scaler.pkl                     # StandardScaler for feature normalization
‚îÇ   ‚îú‚îÄ‚îÄ label_encoders.pkl             # LabelEncoders for categorical features
‚îÇ   ‚îú‚îÄ‚îÄ feature_order.pkl              # Feature ordering (for consistency)
‚îÇ   ‚îú‚îÄ‚îÄ training_history.png           # Training/validation curves
‚îÇ   ‚îú‚îÄ‚îÄ roc_curve.png                  # ROC curve with AUC score
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png           # Confusion matrix heatmap
‚îÇ   ‚îú‚îÄ‚îÄ prediction_distribution.png    # Histogram of predictions
‚îÇ   ‚îî‚îÄ‚îÄ performance_summary.png        # Metrics bar chart
‚îÇ
‚îú‚îÄ‚îÄ disease_tensorflow.py              # Main TensorFlow implementation ‚≠ê
‚îú‚îÄ‚îÄ disease.py                         # Legacy XGBoost (reference only)
‚îú‚îÄ‚îÄ README.md                          # This file
‚îî‚îÄ‚îÄ COMPLETE_GUIDANCE.md               # Detailed implementation guide
```

## üöÄ Quick Start

### Primary Implementation (TensorFlow)
```bash
python disease_tensorflow.py
```

**This script performs all steps automatically:**
1. **Phase 1:** Data loading & preprocessing
2. **Phase 2:** Neural network training
3. **Phase 3:** Model evaluation & metrics
4. **Phase 4:** Generate 5 visualizations
5. **Phase 5:** Interactive prediction interface

### Legacy Implementation (XGBoost - Reference Only)
```bash
python disease.py  # Not recommended - use TensorFlow version
```

## üìä Dataset

**File:** `data/heart_disease.csv`

**Features (21 total):**
- Demographics: Age, Gender
- Vital Signs: Blood Pressure
- Lipids: Cholesterol Level, Triglyceride Level, LDL Cholesterol, HDL Cholesterol
- Medical History: Smoking, Diabetes, Family Heart Disease
- Lifestyle: Exercise Habits, Alcohol Consumption, Stress Level, Sleep Hours, Sugar Consumption
- Health Markers: BMI, High Blood Pressure, Fasting Blood Sugar, CRP Level, Homocysteine Level

**Target:** Heart Disease Status (Binary: Yes/No)

## üß† Neural Network Architecture

### Model Structure (TensorFlow/Keras Sequential)
```
Input Layer
    ‚Üì (20 features - all numeric after preprocessing)
Dense(256, activation='relu', L2=0.001)
    ‚Üì
BatchNormalization()
    ‚Üì
Dropout(0.4)  ‚Üê 40% dropout for regularization
    ‚Üì
Dense(128, activation='relu', L2=0.001)
    ‚Üì
BatchNormalization()
    ‚Üì
Dropout(0.3)  ‚Üê 30% dropout
    ‚Üì
Dense(64, activation='relu', L2=0.001)
    ‚Üì
BatchNormalization()
    ‚Üì
Dropout(0.2)  ‚Üê 20% dropout
    ‚Üì
Dense(32, activation='relu')
    ‚Üì
Dense(16, activation='relu')
    ‚Üì
Dense(1, activation='sigmoid')  ‚Üê Binary output [0, 1]
```

### Key Design Choices:
- **Total Parameters:** ~142,000
- **Optimizer:** Adam (lr=0.001) - Adaptive learning rate optimization
- **Loss Function:** Binary Crossentropy - Standard for binary classification
- **Regularization Techniques:**
  - L2 Penalty (0.001) - Prevents overfitting by penalizing large weights
  - Dropout (0.2-0.4) - Randomly deactivates neurons during training
  - Batch Normalization - Normalizes layer inputs for faster convergence
- **Early Stopping:** Patience=50 - Stops training if validation loss doesn't improve
- **Learning Rate Scheduler:** Reduces LR by 0.5 if no improvement for 10 epochs

## ÔøΩ Data Preprocessing Pipeline

### Step 1: Missing Value Handling
```python
# Numeric columns: Use median (less affected by outliers)
# Categorical columns: Use mode (most frequent value)
```
- **Why median for numeric?** Robust to outliers, appropriate for skewed distributions
- **Why mode for categorical?** Preserves most frequent pattern in data

### Step 2: Categorical Encoding (LabelEncoder)
- Converts categorical strings to numeric integers
- Example: `['Male', 'Female']` ‚Üí `[1, 0]`
- Maintains order consistency across train/test sets

### Step 3: Feature Scaling (StandardScaler)
```
scaled_value = (x - mean) / std_dev
```
- **Why scaling?** Neural networks converge faster with normalized inputs
- Prevents features with larger scales from dominating
- All features now on same scale ~[-3, 3]

### Step 4: Train-Test Split
- **80-20 split:** 80% training, 20% testing
- **Stratification:** Maintains class distribution in both sets
- **Random state:** Ensures reproducibility

### Step 5: Class Weight Balancing
- **Problem:** Dataset may have imbalanced classes (more healthy than diseased)
- **Solution:** Assign higher weights to minority class
- **Effect:** Model learns both classes equally well

## üìä Evaluation Metrics

After training, you'll see:

```
Train Accuracy: XX.XX%
Test Accuracy:  XX.XX%
Train AUC-ROC:  X.XXXX
Test AUC-ROC:   X.XXXX

Classification Report:
              precision    recall  f1-score   support
    No Disease       X.XX      X.XX      X.XX       XXX
       Disease       X.XX      X.XX      X.XX       XXX

Confusion Matrix:
 [[TN  FP]
  [FN  TP]]
```

## üé® Generated Visualizations

1. **01_training_history.png**
   - Training vs Validation Accuracy
   - Training vs Validation Loss
   - Training vs Validation AUC-ROC

2. **02_roc_curve.png**
   - ROC Curve with AUC score
   - Comparison with random classifier

3. **03_confusion_matrix.png**
   - True Negatives, False Positives
   - False Negatives, True Positives

4. **04_prediction_distribution.png**
   - Distribution of predictions for both classes
   - Decision threshold visualization

5. **05_performance_summary.png**
   - Bar chart of: Accuracy, AUC-ROC, Precision, Recall

## üíª Making Predictions

### Interactive Mode
```bash
python complete_system.py
# Select option [1] to make a prediction
# Enter patient details when prompted
```

### Output
```
Patient Details:
  Age: 55
  Gender: Male
  ...
  
‚úÖ LOW RISK: No heart disease detected (Confidence: 87.3%)
```

## üîß Configuration

All configurations are in the scripts:
- `SCRIPT_DIR`: Working directory
- `OUTPUT_DIR`: Model output location
- `DATA_PATH`: Dataset location
- `MODEL_PARAMS`: Neural network hyperparameters

To modify model architecture, edit these sections in the scripts:
```python
model = tf.keras.Sequential([
    # Modify layers here
])
```

## üì¶ Dependencies

```
pandas>=1.3.0
numpy>=1.21.0
tensorflow>=2.10.0
scikit-learn>=1.0.0
matplotlib>=3.4.0
seaborn>=0.11.0
```

Install with:
```bash
pip install pandas numpy tensorflow scikit-learn matplotlib seaborn
```

## ‚ö†Ô∏è Important Notes

1. **First Run:** Always run `train_model.py` or `complete_system.py` first to train the model
2. **Model Path:** The trained model is saved in `train/` directory
3. **Feature Order:** Must maintain consistent feature order between training and prediction
4. **Encoding:** Categorical variables are encoded and must be decoded for display
5. **Scaling:** Features are always scaled before prediction

## üîÑ Migration from Old System

The new TensorFlow-only system replaces:
- `disease.py` (XGBoost) ‚Üí ‚ùå Not used
- `disease_tensorflow.py` (mixed) ‚Üí ‚úÖ Use `train_model.py` or `complete_system.py`

## üìù Files Explanation

| File | Purpose |
|------|---------|
| `train_model.py` | Standalone training with full evaluation |
| `predict.py` | Interactive prediction after training |
| `complete_system.py` | All-in-one solution (train + evaluate + predict) |
| `disease.py` | OLD: XGBoost version (deprecated) |
| `disease_tensorflow.py` | OLD: Mixed implementation (deprecated) |

## üéØ Performance Targets

Typical model performance:
- **Accuracy:** 85-90%
- **AUC-ROC:** 0.90-0.95
- **Precision:** 0.85-0.92
- **Recall:** 0.82-0.88

*Actual values depend on data and hyperparameters*

## üêõ Troubleshooting

### "Model not found" error
**Solution:** Run `train_model.py` or `complete_system.py` first

### "CSV file not found" error
**Solution:** Ensure `data/heart_disease.csv` exists in the same directory

### Out of Memory error
**Solution:** Reduce batch_size in the model configuration

### Low accuracy
**Solution:** 
- Check data quality
- Adjust hyperparameters
- Increase epochs
- Modify model architecture

## üìß Support

For issues or questions about:
- **Data preprocessing:** Check `load_and_prepare_data()` function
- **Model training:** Check `train_model()` function
- **Predictions:** Check `make_prediction()` function

## ‚ú® Features

‚úÖ Pure TensorFlow implementation
‚úÖ Handles missing values
‚úÖ Encodes categorical variables
‚úÖ Balances imbalanced classes
‚úÖ Early stopping to prevent overfitting
‚úÖ Learning rate scheduling
‚úÖ Comprehensive evaluation metrics
‚úÖ Beautiful visualizations
‚úÖ Interactive prediction interface
‚úÖ Model persistence (save/load)
‚úÖ Well documented code
‚úÖ Error handling

## ÔøΩ For More Information

**For detailed technical information**, see **COMPLETE_GUIDANCE.md** which includes:
- Complete system architecture explanation
- Library packages and why TensorFlow was chosen over XGBoost
- Neural network layer-by-layer breakdown
- Data preprocessing pipeline details
- Training and evaluation process explanation
- Output interpretation and metric explanations
- Troubleshooting guide

**For glossary of terms**, see **TERMS.md** which includes:
- Confusion Matrix, Precision, Recall, Accuracy explained
- AUC-ROC, ROC Curve, F1-Score definitions
- Epoch, Loss, Gradient, Learning Rate concepts
- Decision Threshold, Regularization techniques
- Medical-specific concepts (Sensitivity, Specificity, PPV, NPV)

**For project details**, see **LICENSE** which includes:
- Complete team information
- Project requirements and specifications
- Installation instructions
- Technical specifications
- Troubleshooting guide

## ÔøΩ Future Enhancements

- [ ] Cross-validation
- [ ] Hyperparameter tuning with Optuna
- [ ] Model interpretation (SHAP values)
- [ ] API server (Flask/FastAPI)
- [ ] Web interface
- [ ] Real-time prediction monitoring
- [ ] Model versioning

## üë• Development Team

**Adamas University - Python Project**

### Lead Developers
- **Rohit Kumar Adak** - Lead Developer
- **Babin Bid** - Lead Developer

### Developers
- **Ritika Pramanick** - Developer
- **Liza Ghosh** - Developer

## üìÖ Project Timeline

- **Start Date:** November 2025
- **Last Modification:** 8th November 2025
- **Version:** 1.0
- **Status:** ‚úÖ Complete

---

**Created:** November 2025
**Version:** 1.0
**Framework:** TensorFlow 2.x
**License:** MIT (See LICENSE file)
**Institution:** Adamas University
